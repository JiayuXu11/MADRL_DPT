## Abstract
1. **Problem definition/importance：** Decentralized proactive transshipment is **more common** than centralized transshipment in practical scenarios, but **rarely studied** due to the complexity of the problem. We apply MADRL to this problem and see if it can achieve outstanding performance. We also examine whether information sharing and centralization are significantly effective. 
2. **Methodology:** We apply Heterogeneous-Agent Proximal Policy Optimization (HAPPO) on this problem by generating **joint ordering and transshipment polices.** 
3. Results: lower overall costs than other heuristics

proactive transshipment 是实际场景中常见的inventory pooling的strategy。retailer之间可以通过transship 货物来一定程度上规避缺货风险。目前多数研究，based on the assumption that 有一个central controller 可以控制所有零售商的决策。而实际场景中，transship与order的决策往往是每个零售商decentral地确定的，这与这个assumption不相符。而我们将应用多智能体强化学习，来研究这一更符合实际场景的decentralized proactive transshipment 问题。我们采用了HAPPO（Heterogeneous-Agent Proximal Policy Optimization）算法，令每个零售商完全以最大化自身利益为目标，生成订货与调运的联合决策。针对库存管理问题，我们对强化学习算法进行了多项针对性地调整，这有效提升了效果. Our results shows that our algorithms outperform 启发式算法 不论是在central的setting下还是decentral的setting下。以及当策略没有被完全执行时，即部分retailer ignore 强化学习算法给出的决策建议时，整个网络仍有不错的表现。More interestingly, 我们还发现，中心化决策，这一多数文献默认的assumption，并不能给零售商网络带来显著的提升，这表明即便每个零售商根据HAPPO，以最大化自己利益为目标去确定订货与transship决策，从所有零售商的总收益上看仍有相当不错的结果，且这一基于零售商个人利益而驱动的决策建议，将相对于central 利益驱动的决策，更容易被零售商接受并采纳。关于强化学习如何在真实场景进行应用，我们也提供了方法，并且结果表明显著优于heuristic policy。我们的研究也说明了强化学习在解决实际供应链管理中的复杂问题时，具有显著的优势。

Proactive transshipment is a commonly used inventory pooling strategy, where retailers can mitigate the risk of stockouts by transshipping goods among themselves. However, most existing research assumes a centralized decision-making process, where a central controller knows all retailers' information and controls all retailers' decisions. This does not align with the realistic, a decentralized decision-making process where each retailer determines their own transshipment and ordering decisions based on their own infomation. In this study, we apply Multi-Agent Deep Reinforcement Learning (MADRL) to investigate a more realistic problem—— decentralized proactive transshipment, where each retailer aims to maximize their own profit by deciding jointly on ordering and transshipment. We use the Heterogeneous-Agent Proximal Policy Optimization (HAPPO) algorithm and make several targeted adjustments for inventory management, which effectively improves its performance. 
Our results demonstrate that our algorithms outperform heuristic algorithms in both centralized and decentralized settings. More interestingly, we found that centralized decision-making, which is commonly assumed in most literature, does not significantly improve the performance of the overall network. This suggests that our approach, where each retailer determines their ordering and transshipment decisions based on maximizing their own profit using HAPPO which has stronger real-world applicability can lead to impressive performance as well. Furthermore, this highlights the algorithm's practicality in real-world situations, as the overall network continues to perform effectively even when some retailers do not follow the decision recommendations generated by the reinforcement learning algorithm. 



the decision recommendations driven by individual retailer profit are more likely to be accepted than central profit-driven decisions. 

标题：Multi-Agent Deep Reinforcement Learning for Decentralized Proactive Transshipment: Real-World Applicability and Impressive Performance




