## 问题要素
decentral、proactive transship、lost sales、多期、non-stationary，RL
## 文献
1. decentral+transship：目前transship game（decentralized transship）的文章，多是单期的，backlog的。即agent当期没有交付掉的需求，可以在期末通过transship拿到的货物进行交付而不产生backlog的cost。2010年左右有较多文献。
2. proactive transship、lost sales、多期：均为central情况，且多数只考虑transship决策，而没有考虑order决策。仅有少部分考虑联合决策，有一篇OR的研究出了最优的，但是仅限于两个零售商。
3. RL：暂时仅有一篇将pooling和RL结合起来的（效果不是很好，因为没有与任何其他方法作比较），他的设定是reactive transship自动完成，因此模型只需决策订货。（比较像文献1拓展到多期）
## 贡献
1. 库存管理领域，填补了decentral、proactive transship、lost sales、多期的空白
2. 库存管理+RL领域，是首篇 强化学习+proactive transship，且是首篇多智能体强化学习+联合决策 的研究
## 研究内容
1. 管理启示（主要通过不同RL模型之间的横向对比）：
   + 信息共享的价值（无信息共享、$\color{#6aaaf1}{弱信息共享}$、全局信息共享）
   + $\color{#6aaaf1}{中心化决策的价值}$
   + transship订单的匹配机制
   + 利润分配机制（fixed、ratio(单日/$\color{#6aaaf1}{多日}$)、market_ratio(单日/$\color{#6aaaf1}{多日}$)）,ratio需要信息共享才能实施。
2. 强化学习的有效性（主要通过RL模型与baseline的比较）
   + $\color{#6aaaf1}{central }$
   + decentral
   + $\color{#6aaaf1}{灵敏度分析（调整各参数数值，随机lead time，零售商间需求不独立） }$
   + $\color{#6aaaf1}{真实数据集应用}$
## 目前进展
1. 上述除了标蓝的都已实现
2. 分数
   + 仅订货的heuristic：5.48
   + central 订货+transship的heuristic：5.76(+0.28) (100%)
   + decentral 订货+transship的heuristic：5.73 (+0.25) (82.14%)
   + decentral （订货,transship）的RL联合决策:5.79(+0.31) (110.71%)
## 后续计划
1. 全局信息共享的分数很不理想，仅5.61，问题还在排查中
2. transship带来的收益没有那么大，需调大需求波动性
3. 联合决策的baseline正参考某篇文章进行复现
4. decentral的baseline再写一个
5. 看看那篇在两个agent的setting下，联合决策最优的论文
6. 看看end to end 那篇，参考供应链问题下，神经网络是怎么设计的