algorithm_name: 'happo' #'happo' #'heuristic2'  #'happo_continue'
experiment_name: '0503_error__'

# basic setting
model_dir: "C:/Users/Jerry/Desktop/thesis/code/MADRL/MADRL_main/results/TransshipNewEnv/InventoryManagement/happo/0503_time_end_critic_pure_false/models" #"C:/Users/Jerry/Desktop/thesis/code/MADRL/MADRL_main/results/TransshipNewEnv/InventoryManagement/happo/continue_cent_controller1/run_seed_1/models"
n_rollout_threads: 100
num_env_steps: 300000000
num_agents: 3
eval_interval: 20
n_no_improvement_thres: 15
gamma: 0.98

# continue or discrete
action_type: 'discrete'  # ['discrete', 'multi_discrete', 'continue']

# env
alpha: 1
ratio_transship: False
transship_revenue_method: 'constant'
constant_transship_revenue: 0.5
ratio_transship_revenue: 0.6

central_controller: False
obs_transship: 'all_transship'
actor_obs_step: False
train_episode_length: 195

# fluctuation control
entropy_decrease: False
entropy_decrease_list: [0.1,0.01,0.005]
entropy_coef: 0.01
std_y_coef: [10.0,10.0]  # only for continue
std_x_coef: 1.0


# lr
use_linear_lr_decay: False
lr: 5e-4
critic_lr: 1e-3

# model setting
recurrent_N: 2
layer_N: 2
hidden_size: 256
hidden_size_critic: 64 # critic
use_ReLU: False
weight_decay: 0

# ppo
ppo_epoch: 10
use_proper_time_limits: False
use_gae: True
gae_lambda: 0.95
use_clipped_value_loss: True
clip_param: 0.2
critic_learning_pure_returns: False
advantage_pure_returns: False

# normalization
sample_mean_advantage: True
use_valuenorm: True
use_popart: False
use_feature_normalization: False
use_max_grad_norm: True
max_grad_norm: 0.5


instant_info_sharing: False
setting_time_end: True
demand_info_for_critic: ['all_mean','all_std','mean','std']



