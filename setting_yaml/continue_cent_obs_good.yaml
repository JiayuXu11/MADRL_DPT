# 就是把所有agent的意向transship和实际transship都作为state输入进去
algorithm_name: 'happo' #'happo' #'heuristic2'  #'happo_continue'
experiment_name: 'continue_cent_obs_good'
model_dir:  "C:/Users/Jerry/Desktop/thesis/code/MADRL/MADRL_main/results/TransshipNewEnv/InventoryManagement/happo/continue_cent_obs_old_transship_setting/run_seed_1/models"
training_bf: True

std_y_coef: [2.0, 2.0]
std_x_coef: 1.0
use_linear_lr_decay: False
lr: 1e-4
critic_lr: 1e-3
hidden_size: 64
n_rollout_threads: 50
num_env_steps: 300000000
num_agents: 3
num_mini_batch: 1

use_valuenorm: True
use_popart: False
use_proper_time_limits: False
use_gae: True
gae_lambda: 0.95
use_clipped_value_loss: False
clip_param: 0.3
ppo_epoch: 10

eval_interval: 20
n_no_improvement_thres: 10

instant_info_sharing: True

# all_args.std_y_coef=[j/2. for j in all_args.std_y_coef]
# all_args.lr=all_args.lr/2
# all_args.critic_lr=all_args.critic_lr/2
# all_args.model_dir = str(config['run_dir'] / 'models')
# all_args.clip_bound=[(1-all_args.clip_param)**1.5,(1+all_args.clip_param)**1.5]

